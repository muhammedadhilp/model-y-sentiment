"""cust_sentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16086zsFKwTihkAjBVcPkgZRJryhaffg_
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
df=pd.read_csv("/content/reddit_customer_comments1.csv")
df

# There seems to be an issue with the sentiment column as all the values are 1
# So i am going to drop it and do sentiment analysis once  more using textblob
df.drop('sentiment',axis = 1,inplace = True)

# Lets do sentiment analysis on our data using textblob
from textblob import TextBlob

# Function to analyze sentiment using TextBlob
def analyze_sentiment(comment):
    # Create a TextBlob object
    blob = TextBlob(comment)
    # Get polarity score
    polarity = blob.sentiment.polarity
    # Map polarity to sentiment label
    if polarity > 0:
        return 1
    elif polarity == 0:
        return 0
    else:
        return -1

# Apply sentiment analysis to each comment in the DataFrame
df['sentiment'] = df['comment'].apply(analyze_sentiment)

df

print(df.head())
print('****************************************************************')
print(df.tail())
print('****************************************************************')
print(df.isna().sum())

sentiment_counts = df['sentiment'].value_counts()

# Plotting
plt.bar(sentiment_counts.index, sentiment_counts.values)
plt.title('Sentiment Distribution')
plt.xlabel('Sentiment')
plt.ylabel('Frequency')
plt.show()

# As we can see from the bar chart above
# There is a class imbalance in our data where positive sentiments are much higher than the others
# So i have to perform undersampling on this data for better model performance
# i already have the count of number of sentiment class in sentiment_count
# Determine the desired number of samples for each class (e.g., make them equal)
desired_count = sentiment_counts.min()

# Undersample the majority class (positive sentiment)
undersampled_df = pd.concat([
    df[df['sentiment'] == sentiment].sample(desired_count, replace=False)
    for sentiment in sentiment_counts.index
])

# Shuffle the undersampled DataFrame
undersampled_df = undersampled_df.sample(frac=1, random_state=42).reset_index(drop=True)

# Now undersampled_df contains a balanced dataset with an equal number of samples for each sentiment class
undersampled_df.shape

sentiment_counts1 = undersampled_df['sentiment'].value_counts()

# Plotting
plt.bar(sentiment_counts1.index, sentiment_counts1.values)
plt.title('Sentiment Distribution')
plt.xlabel('Sentiment')
plt.ylabel('Frequency')
plt.show()

# Starting preprocessing
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
import string
import re

nltk.download('punkt')
nltk.download('stopwords')

# Function to preprocess a single comment
def preprocess_comment(comment):
    # Lowercasing
    comment = comment.lower()

    # Remove URLs
    comment = re.sub(r'http\S+', '', comment)

    # Remove special characters and non-alphanumeric characters
    comment = re.sub(r'[^a-zA-Z\s]', '', comment)

    # Tokenization
    tokens = word_tokenize(comment)

    # Removing punctuation
    tokens = [token for token in tokens if token not in string.punctuation]

    # Removing stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words]

    # Porter Stemmer
    stemmer = SnowballStemmer("english")
    tokens = [stemmer.stem(token) for token in tokens]

    # Joining tokens
    preprocessed_comment = ' '.join(tokens)

    return preprocessed_comment

# Apply preprocessing to all comments in the DataFrame
undersampled_df['Preprocessed_Comment'] = undersampled_df['comment'].apply(preprocess_comment)
undersampled_df.drop('comment',axis=1,inplace = True) # dropping comment as we have the preprocessed comments in a new column
undersampled_df

# preprocessing is done so niow moving to feature engineering

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score

# Load the preprocessed data

X = undersampled_df['Preprocessed_Comment']
y = undersampled_df['sentiment']

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=42)

# Initialize the TF-IDF vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed

# Fit and transform the training data
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)

# Transform the testing data
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Print the shape of the TF-IDF transformed data
print("Shape of X_train_tfidf:", X_train_tfidf.shape)
print("Shape of X_test_tfidf:", X_test_tfidf.shape)

from sklearn.tree import DecisionTreeClassifier

# Initialize Decision Tree Classifier
clf = DecisionTreeClassifier(random_state=42)

# Train the Model
clf.fit(X_train_tfidf, y_train)

# Evaluate the Model
y_pred = clf.predict(X_test_tfidf)
# Calculate precision
accuracy = accuracy_score(y_test, y_pred)

# Calculate precision
precision = precision_score(y_test, y_pred, average='weighted')

# Calculate recall
recall = recall_score(y_test, y_pred, average='weighted')

# Calculate F1-score
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-score: {f1}")